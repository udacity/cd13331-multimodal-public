{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Moderation System: Personal Information Detection\n",
    "\n",
    "This notebook demonstrates a mock audio moderation system that processes audio recordings to detect and flag personal information disclosure. The system uses Gemini for transcription and analysis, with PydanticAI for structured output handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "\n",
    "import soundfile as sf\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "# Load environment variables\n",
    "assert load_dotenv(\"../.env\"), \"Couldn not load ../.env\"\n",
    "assert \"GEMINI_API_KEY\" in os.environ, \"GEMINI_API_KEY not found in environment variables\"\n",
    "\n",
    "# Only needed on the Udacity workspace. Comment this out if running on another system.\n",
    "os.environ['HF_HOME'] = '/voc/data/huggingface'\n",
    "os.environ['OLLAMA_MODELS'] = '/voc/data/ollama/cache'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ['PATH'] = f\"/voc/data/ollama/bin:/voc/data/ffmpeg/bin:{os.environ.get('PATH', '')}\"\n",
    "os.environ['LD_LIBRARY_PATH'] = f\"/voc/data/ollama/lib:/voc/data/ffmpeg/lib:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models and Policy Definitions\n",
    "\n",
    "Let's assume that a company has a policy preventing people from exchanging customer information during unsecured calls or communications. This could be a possible schema for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "class ViolationType(str, Enum):\n",
    "    PHONE_NUMBER = \"phone_number\"\n",
    "    EMAIL_ADDRESS = \"email_address\"\n",
    "    SSN = \"social_security_number\"\n",
    "    ADDRESS = \"physical_address\"\n",
    "    CREDIT_CARD = \"credit_card_number\"\n",
    "    DATE_OF_BIRTH = \"date_of_birth\"\n",
    "\n",
    "\n",
    "class PolicyViolation(BaseModel):\n",
    "    violation_type: ViolationType\n",
    "    detected_text: str\n",
    "    timestamp_start: Optional[float] = None\n",
    "    context: str = Field(description=\"Surrounding context where violation was detected\")\n",
    "\n",
    "\n",
    "# TODO: Create the ModerationResult data model\n",
    "# (aka output schema) for the model. Include the following\n",
    "# elements:\n",
    "# - transcript: str\n",
    "# - violations_found: List[PolicyViolation]\n",
    "# - risk_level: str (LOW, MEDIUM, or HIGH based on violations)\n",
    "# - recommendations: List[str]\n",
    "class ModerationResult(BaseModel):\n",
    "    ... #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Processing Utilities\n",
    "\n",
    "Let's define some helper utils to prepare data for processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import io\n",
    "from pydantic_ai import Agent, BinaryContent\n",
    "\n",
    "\n",
    "def audio_to_bytes(audio_array, sample_rate):\n",
    "    \"\"\"Convert audio array to bytes for Pydantic AI.\"\"\"\n",
    "    buffer = io.BytesIO()\n",
    "    sf.write(buffer, audio_array, sample_rate, format='WAV')\n",
    "    buffer.seek(0)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "def format_audio_for_gemini(file_path: Path):\n",
    "    \"\"\"Format a single audio sample from the dataset.\"\"\"\n",
    "    audio_array, sample_rate = librosa.load(file_path, sr=None, mono=True)\n",
    "    \n",
    "    # Convert audio to bytes\n",
    "    audio_bytes = audio_to_bytes(\n",
    "        audio_array,\n",
    "        sample_rate\n",
    "    )\n",
    "    \n",
    "    # Create binary content for Pydantic AI\n",
    "    # NOTE: to make this more efficient, we could upload\n",
    "    # audio as mp3 instead of wav\n",
    "    audio_content = BinaryContent(\n",
    "        data=audio_bytes,\n",
    "        media_type='audio/wav'\n",
    "    )\n",
    "    \n",
    "    return audio_array, sample_rate, audio_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PydanticAI Agent Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize the PydanticAI agent with Gemini\n",
    "# and the appropriate output type and system prompt.\n",
    "# Use the 'gemini-2.5-flash-lite' model.\n",
    "# The system prompt should instruct the model to:\n",
    "# 1. Transcribe the audio\n",
    "# 2. Analyze the transcript for personal information violations\n",
    "# 3. Flag any instances of: phone numbers, email addresses, SSN, physical\n",
    "#    addresses, credit card numbers, dates of birth\n",
    "# 4. Assess the overall risk level and provide recommendations\n",
    "moderation_agent = ... #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Moderation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration with Sample Audio\n",
    "\n",
    "We load a sample file and apply our moderation system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "# Analyze a single audio file (modify the filename as needed)\n",
    "sample_file = \"../audio_moderation.mp3\"\n",
    "\n",
    "print(f\"Analyzing: {sample_file}\")\n",
    "\n",
    "# TODO; Prepare audio for API. Call the format_audio_for_gemini\n",
    "# function on the sample_file and collect the audio_array, sample_rate, and audio_content.\n",
    "audio_array, sample_rate, audio_content = ... #complete\n",
    "\n",
    "# TODO: create a list containing a prompt (asking the model to transcribe and\n",
    "# analyze the audio) and the audio itself.\n",
    "message_content = ... #complete\n",
    "\n",
    "# Process with PydanticAI agent\n",
    "result = moderation_agent.run_sync(message_content)\n",
    "\n",
    "print(\"\\n=== ANALYSIS RESULTS ===\")\n",
    "print(\n",
    "    f\"Transcript: {textwrap.fill(result.output.transcript, width=80)}\"\n",
    ")\n",
    "print(f\"Risk Level: {result.output.risk_level}\")\n",
    "print(f\"Violations Found: {len(result.output.violations_found)}\")\n",
    "\n",
    "if result.output.violations_found:\n",
    "    print(\"\\n=== POLICY VIOLATIONS ===\")\n",
    "    for i, violation in enumerate(result.output.violations_found, 1):\n",
    "        print(f\"{i}. {violation.violation_type.value.replace('_', ' ').title()}\")\n",
    "        print(f\"   Detected: {violation.detected_text}\")\n",
    "        print(f\"   Context: {violation.context}\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "for rec in result.output.recommendations:\n",
    "    print(f\"- {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4-moderation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
