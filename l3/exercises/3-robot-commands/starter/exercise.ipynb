{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Command Recognition with Pydantic AI and Gemini\n",
    "\n",
    "This notebook demonstrates how to use Pydantic AI with Gemini to recognize voice commands for a robot control system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Environment\n",
    "\n",
    "Before starting, make sure you have placed your Google Gemini credentials in the `.env` file **in the parent folder**:\n",
    "\n",
    "```bash\n",
    "cp ../env.example ../.env\n",
    "```\n",
    "then edit `../.env` and modify GEMINI_API_KEY with your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, BinaryContent\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "import io\n",
    "import soundfile as sf\n",
    "\n",
    "# Load environment variables\n",
    "assert load_dotenv(\"../.env\"), \"Please prepare a .env file with your GEMINI_API_KEY\"\n",
    "assert os.getenv(\"GEMINI_API_KEY\"), \"GEMINI_API_KEY not found in .env file\"\n",
    "\n",
    "# This is needed to use asyncio within jupyter\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Command Schema\n",
    "\n",
    "We'll use Pydantic models to structure our command recognition output. This ensures consistent output that can be directly used by a robot control system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from typing_extensions import Literal\n",
    "\n",
    "# TODO: define a Pydantic model for the structured output\n",
    "# It should contain:\n",
    "# - action: the recognized robot command (from a predefined set). Use Literal\n",
    "#.  to restrict to valid commands. The commands should be \"move_forward\",\n",
    "#  \"move_backward\", \"turn_left\", \"turn_right\", \"pick_up\", \"put_down\", \"stop\", and \"unknown\"\n",
    "# - target_object: an optional string for the object mentioned in the command, if any\n",
    "# - rationale: a string explaining why this command was recognized\n",
    "class RobotCommand(BaseModel):\n",
    "    \"\"\"Structured output for robot command recognition.\"\"\"\n",
    "\n",
    "    action: ... #complete\n",
    "    \n",
    "    target_object: Optional[str] = Field(\n",
    "        default=None, description=\"Object mentioned in the command, if any\"\n",
    "    )\n",
    "    \n",
    "    rationale: ... #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pydantic AI Agent\n",
    "\n",
    "Set up the agent with Gemini for robot command recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.models.google import GoogleModelSettings\n",
    "\n",
    "\n",
    "# Remove thinking to avoid long delays and timeouts\n",
    "settings = GoogleModelSettings(\n",
    "    google_thinking_config={\"thinking_budget\": 0},\n",
    ")\n",
    "\n",
    "# TODO: create the pydantic ai Agent for this. \n",
    "# For the model, use gemini-2.5-flash-lite. For the prompt,\n",
    "# come up with a good prompt explaing the model that it needs to\n",
    "# recognize robot commands from audio. \n",
    "# Use the RobotCommand model as output_type\n",
    "# and remember to include model_settings=settings to avoid\n",
    "# long thinking times\n",
    "# For the instructions, be structured and precise.\n",
    "command_agent = ... #complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "We'll use the same audio dataset and pretend these are voice commands for our robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "samples = list(Path(\"../samples\").glob(\"*.mp3\"))\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function for Audio Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "\n",
    "def audio_to_bytes(audio_array, sample_rate):\n",
    "    \"\"\"Convert audio array to bytes for Pydantic AI.\"\"\"\n",
    "    buffer = io.BytesIO()\n",
    "    sf.write(buffer, audio_array, sample_rate, format='WAV')\n",
    "    buffer.seek(0)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "def format_audio_for_gemini(file_path: Path):\n",
    "    \"\"\"Format a single audio sample from the dataset.\"\"\"\n",
    "    audio_array, sample_rate = librosa.load(file_path, sr=None, mono=True)\n",
    "    \n",
    "    # Convert audio to bytes\n",
    "    audio_bytes = audio_to_bytes(\n",
    "        audio_array,\n",
    "        sample_rate\n",
    "    )\n",
    "    \n",
    "    # Create binary content for Pydantic AI\n",
    "    audio_content = BinaryContent(\n",
    "        data=audio_bytes,\n",
    "        media_type='audio/wav'\n",
    "    )\n",
    "    \n",
    "    return audio_array, sample_rate, audio_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Command Recognition\n",
    "\n",
    "Analyze one audio sample to see how the system interprets it as a robot command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample to analyze\n",
    "audio_array, sample_rate,audio_content = format_audio_for_gemini(samples[0])\n",
    "\n",
    "\n",
    "# Display the audio\n",
    "display(Audio(audio_array, rate=sample_rate))\n",
    "\n",
    "# TODO: run the command_agent to recognize the command\n",
    "# Hint: use command_agent.run_sync\n",
    "# The input should be a list with two elements:\n",
    "# 1. A string with a short prompt instructing to analyze the audio \n",
    "#    for robot commands.\n",
    "# 2. The audio_content variable\n",
    "result = ... #complete\n",
    "\n",
    "print(\"\\nCommand Recognition Results:\")\n",
    "print(f\"Action: {result.output.action}\")\n",
    "print(f\"Target Object: {result.output.target_object}\")\n",
    "print(f\"Reasoning: {result.output.rationale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Command Analysis\n",
    "\n",
    "Test the system with multiple audio samples to see how it interprets various speech patterns as robot commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing multiple audio samples for robot commands:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for sample_path in samples:\n",
    "\n",
    "    # TODO: format audio for Gemini\n",
    "    # HINT: just call format_audio_for_gemini providing the sample_path\n",
    "    audio_array, sample_rate, audio_content = ... #complete\n",
    "\n",
    "    print(f\"\\nSample {sample_path}\")\n",
    "    display(Audio(audio_array, rate=sample_rate))\n",
    "\n",
    "    # TODO: run agent to recognize the command\n",
    "    # (same syntax as we did in the previous cell)\n",
    "    result = ... #complete\n",
    "\n",
    "    print(f\"Recognized Command: {result.output.action}\")\n",
    "    print(f\"Object: {result.output.target_object or 'None'}\")\n",
    "    print(f\"Reasoning: {result.output.rationale}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3-robot-commands",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
