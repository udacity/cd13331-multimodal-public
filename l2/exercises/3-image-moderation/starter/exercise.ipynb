{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Gemini (Company Policy Moderation)\n",
    "\n",
    "This notebook demonstrates how to use Gemini via Pydantic AI for image classification to enforce company policies. We'll use a fake company policy scenario to show how you might moderate content in a business context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Make sure the `.env` file in the *parent* directory of this notebook is appropriately filled up with your API key for Gemini:\n",
    "\n",
    "```\n",
    "GEMINI_API_KEY=your_api_key_here\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "\n",
    "# Load environment variables\n",
    "assert load_dotenv(\"../.env\"), \"Could not load credentials! Make sure you have a .env file in the parent directory\"\n",
    "\n",
    "# Verify API key is loaded\n",
    "if not os.getenv('GEMINI_API_KEY'):\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this for pydantic AI\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Company Policy Rules\n",
    "\n",
    "Let's imagine we are a company and we need to enforce a policy for the sharing of workplace imagery on social media. Let's define the types of policy violation we want to detect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "# Here we define the possible violation in a Enum\n",
    "class PolicyViolationType(str, Enum):\n",
    "    NONE = \"none\"\n",
    "    UNPROFESSIONAL_ATTIRE = \"unprofessional_attire\"\n",
    "    FOOD_IN_MEETING_ROOM = \"food_in_meeting_room\"\n",
    "    PERSONAL_ITEMS_ON_DESK = \"personal_items_on_desk\"\n",
    "    UNORGANIZED_WORKSPACE = \"unorganized_workspace\"\n",
    "    CONFIDENTIAL_INFO_VISIBLE = \"confidential_info_visible\"\n",
    "\n",
    "\n",
    "# We define the schema (aka data model) for our output\n",
    "class ModerationResult(BaseModel):\n",
    "    \"\"\"Result of company policy moderation check\"\"\"\n",
    "    \n",
    "    # TODO: add a is_compliant field of type boolean and a suitable description. Use the Field class to\n",
    "    # add the description of the parameter\n",
    "    # [field_name]: [field_type] = Field(description=\"...\")\n",
    "    ... # complete\n",
    "    \n",
    "    # TODO: add the violations field with a type corresponding to a *list* of PolicyViolationType.\n",
    "    # Again, use the Field class to add a suitable description\n",
    "    # HINT: you can declare the type as a list by using List[PolicyViolationType]\n",
    "    ... # complete\n",
    "\n",
    "    \n",
    "    # NOTE: a lot of people use a confidence number to try to gather the\n",
    "    # confidence of the detection. Unfortunately, it has been proven that this\n",
    "    # often does not work reliably, LLMs just don't work that way!\n",
    "    # So we won't do it here. There are other techniques to approach this,\n",
    "    # like generating multiple answers and voting, but they go beyond the scope\n",
    "    # of this notebook\n",
    "    # confidence: float = Field(\n",
    "    #     ge=0.0, le=1.0,\n",
    "    #     description=\"Confidence score for the assessment (0-1)\"\n",
    "    # )\n",
    "    explanation: str = Field(\n",
    "        description=\"Brief explanation of the decision\"\n",
    "    )\n",
    "    suggested_action: str = Field(\n",
    "        description=\"Recommended action if policy is violated\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Pydantic AI Agent\n",
    "\n",
    "Now we'll create a Pydantic AI agent that uses Gemini to analyze images and determine if they comply with our company policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.google import GoogleModelSettings\n",
    "\n",
    "\n",
    "# Company policy prompt\n",
    "COMPANY_POLICY_PROMPT = \"\"\"\n",
    "You are a workplace policy compliance agent for TechCorp Inc. Analyze images to ensure they comply with \n",
    "our guidelines for social media sharing:\n",
    "\n",
    "POLICY VIOLATIONS TO CHECK:\n",
    "1. UNPROFESSIONAL_ATTIRE: Overly casual clothing in client-facing areas\n",
    "2. FOOD_IN_MEETING_ROOM: Food or drinks in designated meeting rooms\n",
    "3. PERSONAL_ITEMS_ON_DESK: Excessive personal items cluttering workspace\n",
    "4. UNORGANIZED_WORKSPACE: Messy or unprofessional workspace setup\n",
    "5. CONFIDENTIAL_INFO_VISIBLE: Documents, screens, or whiteboards with sensitive info\n",
    "\n",
    "IMPORTANT:\n",
    "- Be reasonable and consider context\n",
    "- A coffee mug or small personal photo is generally acceptable\n",
    "- Focus on professional appearance and information security\n",
    "- If uncertain, lean toward compliance unless clearly problematic\n",
    "\n",
    "Provide a clear explanation for your decision.\n",
    "\"\"\"\n",
    "\n",
    "model_settings = GoogleModelSettings(\n",
    "    temperature=0.2,  # Range: 0.0 to 2.0, default is 1.0\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# TODO: create the agent with Gemini model. Use gemini-2.5-flash-lite\n",
    "# and remember to set the output_type to our output schema. Also remember\n",
    "# to set system_prompt to our prompt COMPANY_POLICY_PROMPT!\n",
    "moderation_agent = Agent(\n",
    "    ...,  # complete (provide model)\n",
    "    output_type=...,  # complete\n",
    "    system_prompt=...,  # complete\n",
    "    model_settings=model_settings,\n",
    "    retries=3,  # Retry up to 3 times on failure\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Let's create some utility functions to handle image processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "from pydantic_ai import BinaryContent\n",
    "\n",
    "\n",
    "def moderate_image(\n",
    "    img: Image.Image, agent: Agent\n",
    ") -> ModerationResult:\n",
    "\n",
    "    # Limit size to reduce token usage\n",
    "    img.thumbnail((600, 600))\n",
    "\n",
    "    # Format image\n",
    "    image_bytes = BytesIO()\n",
    "    img.save(image_bytes, format=\"JPEG\")\n",
    "\n",
    "    # Run analysis\n",
    "    result = agent.run_sync(\n",
    "        [BinaryContent(data=image_bytes.getvalue(), media_type=\"image/jpeg\")],\n",
    "    )\n",
    "\n",
    "    return result.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Simulated Image Analysis\n",
    "\n",
    "Since we can't include actual images in this demo, we'll use a trick: we will generate image with Gemini and have another Gemini moderate them. This way we can generate as much data as we want! (although it might get expensive, and in practice a smaller, more targeted image-generation model might be more viable for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a pydantic data model for a test case scenario\n",
    "class TestScenario(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    expected_moderation_result: PolicyViolationType\n",
    "\n",
    "# We define a few scenarios\n",
    "test_scenarios = [\n",
    "    TestScenario(\n",
    "        name=\"Clean Professional Workspace\",\n",
    "        description=\"a view of a person on a web call in a professional context\",\n",
    "        expected_moderation_result=PolicyViolationType.NONE,\n",
    "    ),\n",
    "    TestScenario(\n",
    "        name=\"Messy Desk with Food\",\n",
    "        description=\"a desk covered with pizza boxes, multiple drinks, papers scattered everywhere, and personal items like toys and photos covering the workspace.\",\n",
    "        expected_moderation_result=PolicyViolationType.FOOD_IN_MEETING_ROOM,\n",
    "    ),\n",
    "    # TODO: add a few test scenarios yourself!\n",
    "    # Remember: the description is used to generate an image as well\n",
    "    ... # complete,\n",
    "]\n",
    "\n",
    "print(f\"Created {len(test_scenarios)} test scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Analysis\n",
    "\n",
    "Let's run our moderation agent on the test scenarios.\n",
    "\n",
    "> *NOTE*: in a real use case, even if you used simulated data you would have to repeat each test scenario many times and determine for example the proportion of times the appropriate violation is contained in the list of violations returned by the model. Here we don't do that because it would take a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "\n",
    "def generate_and_moderate_image(test_scenario: TestScenario, moderation_agent: Agent):\n",
    "    # Initialize Gemini client (make sure you have GEMINI_API_KEY env var set)\n",
    "    client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "    prompt = f\"Create an image of {test_scenario.description}.\"\n",
    "\n",
    "    generated_image = None\n",
    "\n",
    "    # Try 10 times to generate an image. This is necessary because sometimes\n",
    "    # the model may not generate an image on the first try due to potential\n",
    "    # moderation issues on the Gemini side\n",
    "    for _ in range(10):\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-image-preview\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.5,\n",
    "                seed=42\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            if part.inline_data is not None:\n",
    "                generated_image = Image.open(BytesIO(part.inline_data.data))\n",
    "\n",
    "        if generated_image is None:\n",
    "            # No image was generated, retry\n",
    "            print(\"No image generated, retrying...\")\n",
    "            continue\n",
    "        else:\n",
    "            # We successfully generated an image, no need to retry\n",
    "            break\n",
    "\n",
    "    if generated_image is None:\n",
    "        raise ValueError(\"No image was generated from the description\")\n",
    "\n",
    "    # Run moderation on the generated image\n",
    "    moderation_result = moderate_image(generated_image, moderation_agent)\n",
    "\n",
    "    return {\n",
    "        \"test_scenario\": test_scenario,\n",
    "        \"generated_image\": generated_image,\n",
    "        \"moderation_result\": moderation_result.model_dump(),\n",
    "    }\n",
    "\n",
    "\n",
    "for test_scenario in test_scenarios:\n",
    "\n",
    "    result = generate_and_moderate_image(test_scenario, moderation_agent)\n",
    "    _ = plt.imshow(result[\"generated_image\"])\n",
    "    _ = plt.axis(\"off\")\n",
    "    _ = plt.show()\n",
    "    print(f\"{textwrap.fill(result['moderation_result']['explanation'])}\")\n",
    "    print(f\"Violations: {[x.value for x in result['moderation_result']['violations']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3-image-moderation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
