{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Description with Pydantic AI and Gemini\n",
    "\n",
    "This notebook demonstrates how to use Pydantic AI with Gemini 2.5 Flash to generate detailed descriptions of video content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Environment\n",
    "\n",
    "Before starting, make sure you have placed your Google Gemini credentials in the `.env` file:\n",
    "\n",
    "```bash\n",
    "cp env.example .env\n",
    "```\n",
    "then edit `.env` and modify GEMINI_API_KEY with your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, BinaryContent\n",
    "from IPython.display import Video, display\n",
    "\n",
    "# Load environment variables\n",
    "assert load_dotenv(), \"Please prepare a .env file with your GEMINI_API_KEY\"\n",
    "assert os.getenv(\"GEMINI_API_KEY\"), \"GEMINI_API_KEY not found in .env file\"\n",
    "\n",
    "# This is needed to use asyncio within jupyter\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Response Schema\n",
    "\n",
    "We'll use Pydantic models to structure our video description output. This ensures consistent, structured responses that can be easily processed downstream. For example, you could use this in a content management system to automatically tag and categorize videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import Literal\n",
    "\n",
    "\n",
    "class VideoDescription(BaseModel):\n",
    "    \"\"\"Structured output for video content analysis.\"\"\"\n",
    "\n",
    "    summary: str = Field(\n",
    "        description=\"A concise 2-3 sentence summary of what happens in the video\"\n",
    "    )\n",
    "\n",
    "    quality: Literal[\n",
    "        \"poor\",\n",
    "        \"ok\",\n",
    "        \"good\",\n",
    "    ] = Field(description=\"Overall technical quality of the video (e.g., resolution, stability)\")\n",
    "    \n",
    "    main_subjects: List[str] = Field(\n",
    "        description=\"Key people, objects, or animals visible in the video\"\n",
    "    )\n",
    "    \n",
    "    setting: str = Field(\n",
    "        description=\"Description of the location/environment where the video takes place\"\n",
    "    )\n",
    "    \n",
    "    visual_style: str = Field(\n",
    "        description=\"Description of the video's visual characteristics (lighting, colors, camera work, etc.)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pydantic AI Agent\n",
    "\n",
    "Set up the agent with Gemini for video content analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.models.google import GoogleModelSettings\n",
    "\n",
    "\n",
    "# Remove thinking to avoid long delays and timeouts\n",
    "settings = GoogleModelSettings(\n",
    "    google_thinking_config={\"thinking_budget\": 0},\n",
    ")\n",
    "\n",
    "video_agent = Agent(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    output_type=VideoDescription,\n",
    "    instructions=\"\"\"\n",
    "    You are an expert video content analyzer. Watch the provided video carefully and provide:\n",
    "    1. A clear summary of what happens\n",
    "    2. Identification of main subjects (people, objects, animals)\n",
    "    3. Description of the setting/environment\n",
    "    4. Key actions taking place\n",
    "    5. Visual style characteristics\n",
    "    6. Overall mood and tone\n",
    "    7. Duration estimate\n",
    "    8. Any notable or interesting details\n",
    "\n",
    "    Be detailed but concise. Focus on what you can actually observe in the video.\n",
    "    \"\"\",\n",
    "    model_settings=settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function for Video Processing\n",
    "\n",
    "Let's define a helper function to load and format video files for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video_for_analysis(video_path):\n",
    "    \"\"\"Load video file and format it for Pydantic AI.\"\"\"\n",
    "    with open(video_path, 'rb') as f:\n",
    "        video_bytes = f.read()\n",
    "    \n",
    "    # Create binary content for Pydantic AI\n",
    "    # (see note at the end about using File API for longer videos)\n",
    "    video_content = BinaryContent(\n",
    "        data=video_bytes,\n",
    "        media_type='video/mp4'  # Adjust based on your video format\n",
    "    )\n",
    "    \n",
    "    return video_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Analysis\n",
    "\n",
    "Analyze a video file to see the structured description output. Make sure to place your video file in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"dog.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'main_subjects': ['dog', 'yellow cones', 'person'],\n",
      " 'quality': 'good',\n",
      " 'setting': 'outdoor grassy field with agility equipment',\n",
      " 'summary': 'A dog is seen running through a series of yellow cones on a '\n",
      "            'grassy field. A person is visible in the background, seemingly '\n",
      "            'guiding or encouraging the dog.',\n",
      " 'visual_style': 'daylight, eye-level shot, clear focus on the dog and cones'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Replace with your video file path\n",
    "video_path = \"dog.mp4\"  # Change this to your video file\n",
    "\n",
    "# Display the video in the notebook\n",
    "print(\"Original video:\")\n",
    "display(Video(video_path))\n",
    "\n",
    "# Load and analyze the video\n",
    "video_content = load_video_for_analysis(video_path)\n",
    "\n",
    "print(\"\\nAnalyzing video content...\")\n",
    "result = video_agent.run_sync(\n",
    "    [\"Please provide a detailed description of this video.\", video_content]\n",
    ")\n",
    "\n",
    "print(\"\\nVideo Analysis Results:\")\n",
    "\n",
    "pprint(result.output.model_dump(), width=80, depth=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing longer videos\n",
    "\n",
    "If you want to analyze a longer video, you will need to use the File API:\n",
    "```python\n",
    "myfile = client.files.upload(file=\"path/to/video.mp4\")\n",
    "\n",
    "result = video_agent.run_sync(\n",
    "    [\"Please provide a detailed description of this video.\", myfile]\n",
    ")\n",
    "```\n",
    "Unfortunately, the file API is not supported in our testing environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2-video-understanding-with-fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
