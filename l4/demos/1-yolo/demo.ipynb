{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv9 Video Object Detection\n",
    "\n",
    "This notebook demonstrates object detection on video files using YOLOv9 with MIT license.\n",
    "\n",
    "**Key Features:**\n",
    "- Uses MIT-licensed YOLO implementation\n",
    "- Processes video frame by frame\n",
    "- Saves output video with detections\n",
    "\n",
    "> _NOTE_: here we use a MIT-licensed implementation of YOLO. It implements YOLOv9. There are many versions of YOLO around, many of which require enterprise licenses to be used in any commercial context. This version of YOLO is currently the best open one, but there are other non-open versions that could be better for your task. It's up to you to decide what fits your use case best, but the usage is always similar so you will be able to apply what you learn here no matter your choice.\n",
    "\n",
    "## Part 1: detecting objects in a video frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define video paths\n",
    "input_video = \"cars_on_bridge.mp4\"\n",
    "output_video = \"output_detected.m4v\"\n",
    "\n",
    "# Only needed on the Udacity workspace. Comment this out if running on another system.\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/voc/data/huggingface'\n",
    "os.environ['OLLAMA_MODELS'] = '/voc/data/ollama/cache'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ['PATH'] = f\"/voc/data/ollama/bin:/voc/data/ffmpeg/bin:{os.environ.get('PATH', '')}\"\n",
    "os.environ['LD_LIBRARY_PATH'] = f\"/voc/data/ollama/lib:/voc/data/ffmpeg/lib:{os.environ.get('LD_LIBRARY_PATH', '')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a small utility function to get frame rate (FPS) and size of the video (the size of each frame in pixels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "def get_fps_and_video_size(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Get frame size\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    \n",
    "    return fps, (frame_width, frame_height)\n",
    "\n",
    "fps, frame_size = get_fps_and_video_size(input_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv9 Inference on Video\n",
    "\n",
    "Because this is a custom code, we need to do a bit of work to get this to run. First, let's define a helper function to load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 22:29:47] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üöú Building YOLO                                                            <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 22:29:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üöú Building YOLO                                                            \u001b]8;id=286393;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=814685;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building backbone                                                      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building backbone                                                      \u001b]8;id=725885;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=726380;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building neck                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building neck                                                          \u001b]8;id=769383;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=740015;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building head                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building head                                                          \u001b]8;id=418200;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=915513;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building detection                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building detection                                                     \u001b]8;id=719320;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=234175;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building auxiliary                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building auxiliary                                                     \u001b]8;id=476928;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=156208;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 22:29:48] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ‚úÖ Success load model &amp; weight                                             <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 22:29:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ‚úÖ Success load model & weight                                             \u001b]8;id=92879;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=341510;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\u001b\\\u001b[2m189\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üß∏ Found no stride of model, performed a dummy test for      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">bounding_box_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">346</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         auto-anchor size                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üß∏ Found no stride of model, performed a dummy test for      \u001b]8;id=770630;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\u001b\\\u001b[2mbounding_box_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=709271;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\u001b\\\u001b[2m346\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         auto-anchor size                                             \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hydra import compose, initialize_config_module\n",
    "from omegaconf import DictConfig\n",
    "import torch\n",
    "\n",
    "from yolo.tools.solver import InferenceModel\n",
    "\n",
    "\n",
    "def get_model_instance(input_video: str) -> tuple[InferenceModel, DictConfig]:\n",
    "\n",
    "    # Select device (use GPU if available)\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    )\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # This is necssary to avoid issues with tensors on different devices\n",
    "    # for this particular version of YOLO\n",
    "    torch.set_default_device(device)\n",
    "\n",
    "    # We load the default YOLO configuration, then we override some of its parameters\n",
    "    # (this is the hidiomatic way of doing things for Hydra, a configuration management tool)\n",
    "    with initialize_config_module(config_module=\"yolo.config\", version_base=None):\n",
    "        cfg = compose(\n",
    "            config_name=\"config\",\n",
    "            # These are the parameters we want to override\n",
    "            overrides=[\n",
    "                \"task.task=inference\",\n",
    "                # v9-s is the smallest model\n",
    "                \"model=v9-s\",\n",
    "                # We point to our video file\n",
    "                f\"task.data.source={input_video}\",\n",
    "                # We do not want to track on Weights and Biases\n",
    "                \"use_wandb=false\",\n",
    "                # We set out device\n",
    "                f\"device={device}\",\n",
    "            ],\n",
    "        )\n",
    "    # This is the way of loading and setting up a model\n",
    "    # with this version of YOLOv7\n",
    "    model = InferenceModel(cfg).to(device)\n",
    "    model.eval()\n",
    "    # This is a custom step that is necessary to setup the\n",
    "    # post-processing step of the model (which includes the \n",
    "    # Non-Maximum Suppression)\n",
    "    model.setup(cfg.task.task)\n",
    "\n",
    "    return model, cfg\n",
    "\n",
    "\n",
    "model, cfg = get_model_instance(input_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:06<00:00,  8.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from yolo.tools.data_augmentation import PadAndResize\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torch.amp import autocast\n",
    "\n",
    "\n",
    "def preprocess_frame(\n",
    "    frame: np.ndarray,\n",
    "    pad_and_resize: PadAndResize,\n",
    "    device: str = \"cpu\",\n",
    ") -> tuple[torch.Tensor, torch.Tensor, Image.Image]:\n",
    "    # We need to pad and resize every frame to match the expected\n",
    "    # input resolution of the model\n",
    "\n",
    "    frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    untransformed_frame = frame.copy()\n",
    "\n",
    "    # PadAndResize can also operate on the ground truth boxes,\n",
    "    # which we don't have here (because this is inference on unknown data)\n",
    "    # So we use a dummy tensor\n",
    "    fake_boxes = torch.zeros((1, 6))\n",
    "    transformed_frame, _, transform_info = pad_and_resize(frame, fake_boxes)\n",
    "    transformed_frame = to_tensor(transformed_frame)\n",
    "    batch_of_one = transformed_frame[None]\n",
    "    rev_tensor = transform_info[None]\n",
    "\n",
    "    batch_of_one = batch_of_one.to(device)\n",
    "    rev_tensor = rev_tensor.to(device)\n",
    "\n",
    "    return batch_of_one, rev_tensor, untransformed_frame\n",
    "\n",
    "\n",
    "def run_inference_on_one_frame(\n",
    "    model: InferenceModel, frame: np.ndarray, pad_and_resize: Callable\n",
    ") -> list:\n",
    "    \n",
    "    # Pre-process the frame and get:\n",
    "    # the batch of one (the pre-processed frame ready to be fed to the model)\n",
    "    # the rev_tensor (the information needed to reverse the transformations)\n",
    "    # the untransformed_frame (the original frame, needed for visualization)\n",
    "    batch_of_one, rev_tensor, untransformed_frame = preprocess_frame(\n",
    "        frame, pad_and_resize, device=model.device\n",
    "    )\n",
    "\n",
    "    # Run YOLO. This will return the raw outputs of the model\n",
    "    outputs = model(batch_of_one)\n",
    "\n",
    "    # Re-format outputs and apply Non-Maximum Suppression to remove\n",
    "    # duplicate detections\n",
    "    predicts = model.post_process(outputs, rev_tensor=rev_tensor)\n",
    "\n",
    "    # We expect only one element in the batch (one frame)\n",
    "    assert len(predicts) == 1\n",
    "\n",
    "    return untransformed_frame, predicts[0].detach().cpu()\n",
    "\n",
    "def run_inference_on_video(\n",
    "    model: InferenceModel, input_video: str\n",
    ") -> list:\n",
    "\n",
    "    # We use opencv to loop through the frames of the video\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    # Get the total number of frames in the video\n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # We need to pad and resize every frame to match the expected\n",
    "    # input resolution of the model\n",
    "    pad_and_resize = PadAndResize(cfg.image_size)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # NOTE: this is absolutely necessary for good results with this\n",
    "        # version of YOLO. Failing to do this will result in very poor\n",
    "        # performance, because of the way the model has been trained.\n",
    "        with autocast(model.device.type):\n",
    "\n",
    "            for _ in tqdm(range(n_frames), total=n_frames):\n",
    "\n",
    "                # Read frame from the video\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                if not ret:\n",
    "                    # Video is finished\n",
    "                    break\n",
    "\n",
    "                untransformed_frame, predicts = run_inference_on_one_frame(\n",
    "                    model, frame, pad_and_resize\n",
    "                )\n",
    "\n",
    "                # Append results for this frame\n",
    "                results.append([untransformed_frame, predicts])\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = run_inference_on_video(model, input_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Display Results\n",
    "\n",
    "Now we write a little utility function that transforms the results into images with the boxes overlayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo.tools.drawer import draw_bboxes\n",
    "\n",
    "\n",
    "def visualize(results, class_list):\n",
    "        \n",
    "        return [\n",
    "            draw_bboxes(origin_frame, predicts, idx2label=class_list)\n",
    "            for origin_frame, predicts in results\n",
    "        ]\n",
    "\n",
    "frames = visualize(results, cfg.dataset.class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally let's transform the frames into a video so we can see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as output.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"output.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Video\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "def frames_to_video(frames, output_name='output.mp4', fps=5):\n",
    "\n",
    "    # Read first frame to get dimensions\n",
    "    first_frame = frames[0] # type: PIL.Image.Image\n",
    "    width, height = first_frame.size\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_name, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Add frames to video\n",
    "    for frame in frames:\n",
    "        # Convert RGB -> BGR\n",
    "        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Video saved as {output_name}\")\n",
    "    return output_name\n",
    "\n",
    "video_file = frames_to_video(frames, fps=fps, output_name=\"output.mp4\")\n",
    "\n",
    "display(\n",
    "        Video(\"output.mp4\", embed=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that things are working, but the cars are not detected anymore when they get far enough on the bridge. This is a typical problem with YOLO system, we will see in part 2 how to approach that.\n",
    "\n",
    "## Part 2: Object tracking in videos\n",
    "\n",
    "In this second part we are going to move from merely detecting objects independently frame by frame, to tracking each object through the frames. We are going to use the `supervision` library, so let's start by importing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ByteTrack: track objects across frames\n",
    "\n",
    "ByteTrack is a multi-object tracking algorithm that associates object detections across video frames to create consistent tracks (trajectories) for each object.\n",
    "\n",
    "It works in two steps:\n",
    "\n",
    "1. High-confidence association: Match high-confidence detections with existing tracks using similarity measures (IoU overlap + motion prediction based on previous frames)\n",
    "2. Low-confidence recovery: Match remaining unmatched tracks with low-confidence detections that were initially ignored\n",
    "\n",
    "In practice, BytesTrack starts new tracks for unmatched high-confidence detections, keep tracks alive briefly when unmatched, delete tracks unmatched too long. This allows it to recover from brief occlusions and to handle appearing objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's define a class that encapsulates what we need to do to track objects in videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOVideoTrackerBasic:\n",
    "    \"\"\"\n",
    "    A class that encapsulates the logic for tracking objects in a video using YOLO and ByteTrack.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, video_file: str):\n",
    "\n",
    "        self.model, self.cfg = get_model_instance(video_file)\n",
    "\n",
    "        # Get FPS\n",
    "        fps, image_size = get_fps_and_video_size(video_file)\n",
    "\n",
    "        # This is the algorithm that does the tracking.\n",
    "        # We're using the default parameters here, but\n",
    "        # you can tune them if you want to.\n",
    "        self.byte_tracker = sv.ByteTrack(frame_rate=fps)\n",
    "\n",
    "        self.bounding_box_annotator = sv.BoxAnnotator()\n",
    "        self.label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "        # We need to pad and resize every frame to match the expected\n",
    "        # input resolution of the model\n",
    "        self.pad_and_resize = PadAndResize(cfg.image_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def yolo_to_sv_detections(yolo_outputs: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Re-organize information in the format expected by the supervision tracker\n",
    "        \"\"\"\n",
    "\n",
    "        yolo_outputs = yolo_outputs.cpu().numpy()\n",
    "\n",
    "        detections = sv.Detections(\n",
    "            # yolo_outputs is a tensor of shape (n_detections, 6)\n",
    "            # where each detection is (class_id, x1, y1, x2, y2, score)\n",
    "            xyxy=yolo_outputs[:, 1:5],  # box coordinates\n",
    "            confidence=yolo_outputs[:, 5],  # confidence score\n",
    "            class_id=yolo_outputs[:, 0].astype(int),  # class id as integer\n",
    "        )\n",
    "\n",
    "        return detections\n",
    "\n",
    "    def _yolo_inference(self, image_slice: np.ndarray) -> sv.Detections:\n",
    "        \"\"\"\n",
    "        Runs inference on one frame and returns results in the format \n",
    "        expected by the supervision tracker\n",
    "        \"\"\"\n",
    "        _, predicts = run_inference_on_one_frame(\n",
    "            self.model, image_slice, self.pad_and_resize\n",
    "        )\n",
    "        return self.yolo_to_sv_detections(predicts)\n",
    "\n",
    "    def run_on_one_frame(self, frame: np.ndarray, index: int) -> np.ndarray:\n",
    "\n",
    "        detections = self._yolo_inference(frame)\n",
    "        # We update the tracker with the new detections\n",
    "        detections = self.byte_tracker.update_with_detections(detections)\n",
    "\n",
    "        labels = [\n",
    "            f\"{cfg.dataset.class_list[int(class_id)]} {tracker_id} {confidence:0.2f}\"\n",
    "            for _, class_id, confidence, tracker_id in zip(\n",
    "                detections.xyxy,\n",
    "                detections.class_id,\n",
    "                detections.confidence,\n",
    "                detections.tracker_id,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        annotated_frame = self.bounding_box_annotator.annotate(\n",
    "            scene=frame.copy(), detections=detections\n",
    "        )\n",
    "\n",
    "        annotated_frame = self.label_annotator.annotate(\n",
    "            scene=annotated_frame, detections=detections, labels=labels\n",
    "        )\n",
    "\n",
    "        return annotated_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 23:58:40] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üöú Building YOLO                                                            <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 23:58:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üöú Building YOLO                                                            \u001b]8;id=42860;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=764855;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building backbone                                                      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building backbone                                                      \u001b]8;id=133994;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=852863;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 23:58:41] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building neck                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 23:58:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building neck                                                          \u001b]8;id=548501;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=725085;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building head                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building head                                                          \u001b]8;id=832734;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=259865;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building detection                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building detection                                                     \u001b]8;id=984050;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=645125;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building auxiliary                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building auxiliary                                                     \u001b]8;id=299920;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=353594;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ‚úÖ Success load model &amp; weight                                             <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ‚úÖ Success load model & weight                                             \u001b]8;id=578293;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=803177;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\u001b\\\u001b[2m189\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üß∏ Found no stride of model, performed a dummy test for      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">bounding_box_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">346</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         auto-anchor size                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üß∏ Found no stride of model, performed a dummy test for      \u001b]8;id=276763;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\u001b\\\u001b[2mbounding_box_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=792369;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\u001b\\\u001b[2m346\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         auto-anchor size                                             \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99392b7f9e5948aa92e27c4224a70eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing video:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_video = \"cars_on_bridge.mp4\"\n",
    "output_video = \"output_detected.m4v\"\n",
    "\n",
    "processor = YOLOVideoTrackerBasic(video_file=input_video)\n",
    "\n",
    "\n",
    "# Supervision makes it very easy to apply a processing function\n",
    "# to every frame of a video and save the result to a new video file\n",
    "sv.process_video(\n",
    "    source_path=input_video,\n",
    "    target_path=output_video,\n",
    "    callback=processor.run_on_one_frame,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# Convert from m4v to mp4 so we can display it here\n",
    "!ffmpeg -i {output_video} -c:v libx264 -tag:v avc1 cars_on_bridge_detected_orig.mp4 -y > /dev/null 2>&1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"cars_on_bridge_detected_orig.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(\n",
    "        Video(\"cars_on_bridge_detected_orig.mp4\", embed=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that objects keep their \"identity\" throught the video. This is the core concept of object tracking! However, the car detections are still disappearing towards the end, let's fix that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the small objects problem\n",
    "\n",
    "Detecting small objects is a known challenge for YOLO algorithms. A small object is defined as an object with a typical size that is much smaller than the dimension of the image. \n",
    "\n",
    "We can see this happening in the video above: as the cars become smaller, the detections become unstable and then cars are not detected anymore.\n",
    "\n",
    "There is a basic trick that works quite well in practice: we divide the image in sub-images with overlap, run YOLO independently on each, then remove redundant detections. This is accomplished in `supervision` by using the `sv.InferenceSlider` class. Let's add it to our detector class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOVideoTrackerWithSlicing:\n",
    "    \"\"\"\n",
    "    A class that encapsulates the logic for tracking objects in a video using YOLO and ByteTrack.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, video_file: str, with_slicing: bool = True\n",
    "    ):\n",
    "        \n",
    "        self.model, self.cfg = get_model_instance(video_file)\n",
    "\n",
    "        # Get FPS\n",
    "        fps, image_size = get_fps_and_video_size(video_file)\n",
    "\n",
    "        # This is the algorithm that does the tracking.\n",
    "        # We're using the default parameters here, but\n",
    "        # you can tune them if you want to.\n",
    "        self.byte_tracker = sv.ByteTrack(frame_rate=fps)\n",
    "\n",
    "        self.bounding_box_annotator = sv.BoxAnnotator()\n",
    "        self.label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "        # We need to pad and resize every frame to match the expected\n",
    "        # input resolution of the model\n",
    "        self.pad_and_resize = PadAndResize(cfg.image_size)\n",
    "\n",
    "        if with_slicing:\n",
    "            self.slicer = sv.InferenceSlicer(\n",
    "                # We slice the image with overlapping slices of\n",
    "                # size half the image size, with an overlap of one sixth\n",
    "                # of the image size\n",
    "                slice_wh=(image_size[0] // 2, image_size[1] // 2),\n",
    "                overlap_wh=((image_size[0] // 6), (image_size[1] // 6)),\n",
    "                # This is the function that will be called on each slice\n",
    "                callback=self._yolo_inference,\n",
    "                overlap_ratio_wh=None,  # this is just to avoid a warning\n",
    "            )\n",
    "        else:\n",
    "            # No slicing, just run YOLO on the whole image\n",
    "            self.slicer = self._yolo_inference\n",
    "\n",
    "    @staticmethod\n",
    "    def yolo_to_sv_detections(yolo_outputs: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Re-organize information in the format expected by the supervision tracker\n",
    "        \"\"\"\n",
    "\n",
    "        yolo_outputs = yolo_outputs.cpu().numpy()\n",
    "\n",
    "        detections = sv.Detections(\n",
    "            # yolo_outputs is a tensor of shape (n_detections, 6)\n",
    "            # where each detection is (class_id, x1, y1, x2, y2, score)\n",
    "            xyxy=yolo_outputs[:, 1:5],  # box coordinates\n",
    "            confidence=yolo_outputs[:, 5],  # confidence score\n",
    "            class_id=yolo_outputs[:, 0].astype(int),  # class id as integer\n",
    "        )\n",
    "\n",
    "        return detections\n",
    "\n",
    "    def _yolo_inference(self, image_slice: np.ndarray) -> sv.Detections:\n",
    "        \"\"\"\n",
    "        Runs inference on one frame and returns results in the format\n",
    "        expected by the supervision tracker\n",
    "        \"\"\"\n",
    "        _, predicts = run_inference_on_one_frame(\n",
    "            self.model, image_slice, self.pad_and_resize\n",
    "        )\n",
    "        return self.yolo_to_sv_detections(predicts)\n",
    "\n",
    "    def run_on_one_frame(self, frame: np.ndarray, index: int) -> np.ndarray:\n",
    "\n",
    "        detections = self.slicer(frame)\n",
    "        # We update the tracker with the new detections\n",
    "        detections = self.byte_tracker.update_with_detections(detections)\n",
    "\n",
    "        labels = [\n",
    "            f\"{cfg.dataset.class_list[int(class_id)]} {tracker_id} {confidence:0.2f}\"\n",
    "            for _, class_id, confidence, tracker_id in zip(\n",
    "                detections.xyxy,\n",
    "                detections.class_id,\n",
    "                detections.confidence,\n",
    "                detections.tracker_id,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        annotated_frame = self.bounding_box_annotator.annotate(\n",
    "            scene=frame.copy(), detections=detections\n",
    "        )\n",
    "\n",
    "        annotated_frame = self.label_annotator.annotate(\n",
    "            scene=annotated_frame, detections=detections, labels=labels\n",
    "        )\n",
    "\n",
    "        return annotated_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 23:59:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üöú Building YOLO                                                            <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 23:59:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üöú Building YOLO                                                            \u001b]8;id=160909;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=495745;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building backbone                                                      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building backbone                                                      \u001b]8;id=331670;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=879127;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building neck                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building neck                                                          \u001b]8;id=917255;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=994148;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building head                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building head                                                          \u001b]8;id=412040;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=510574;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building detection                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building detection                                                     \u001b]8;id=357617;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=271682;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building auxiliary                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building auxiliary                                                     \u001b]8;id=18909;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=733451;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 23:59:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ‚úÖ Success load model &amp; weight                                             <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 23:59:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ‚úÖ Success load model & weight                                             \u001b]8;id=265255;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=35186;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\u001b\\\u001b[2m189\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üß∏ Found no stride of model, performed a dummy test for      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">bounding_box_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">346</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         auto-anchor size                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üß∏ Found no stride of model, performed a dummy test for      \u001b]8;id=475413;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\u001b\\\u001b[2mbounding_box_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=665925;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\u001b\\\u001b[2m346\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         auto-anchor size                                             \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbed3cbaf524aba967ab8e491bc4509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing video:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"cars_on_bridge_detected_2.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_video = \"cars_on_bridge.mp4\"\n",
    "output_video = \"output_detected.m4v\"\n",
    "\n",
    "processor = YOLOVideoTrackerWithSlicing(video_file=input_video, with_slicing=True)\n",
    "\n",
    "sv.process_video(\n",
    "    source_path=input_video,\n",
    "    target_path=output_video,\n",
    "    callback=processor.run_on_one_frame,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# Convert from m4v to mp4 so we can display it here\n",
    "!ffmpeg -i {output_video} -c:v libx264 -tag:v avc1 cars_on_bridge_detected_2.mp4 -y > /dev/null 2>&1\n",
    "\n",
    "display(\n",
    "        Video(\"cars_on_bridge_detected_2.mp4\", embed=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object counting\n",
    "\n",
    "Now that our detections are of better quality, we can see one more common application of these technologies: object counting. In a typical scenario, we want to count how many objects enter or exit a certain area. In the case of our bridge, this would allow us for example to count how many vehicles pass on the bridge in a given unit of time, for traffic planning purposes.\n",
    "\n",
    "With `supervision` this is easy to do: we need to define a line on the video, then the library can count how many vehicles cross that line in either directions (\"in\" or \"out\"). Let's extend our class for this use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOVideoObjectCounter:\n",
    "    \"\"\"\n",
    "    A class that encapsulates the logic for counting objects in a video using YOLO and ByteTrack.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        video_file: str,\n",
    "        with_slicing: bool = True,\n",
    "        line_zone: sv.LineZone = None,\n",
    "    ):\n",
    "        \n",
    "        self.model, self.cfg = get_model_instance(video_file)\n",
    "\n",
    "        # Get FPS\n",
    "        fps, image_size = get_fps_and_video_size(video_file)\n",
    "\n",
    "        # This is the algorithm that does the tracking.\n",
    "        # We're using the default parameters here, but\n",
    "        # you can tune them if you want to.\n",
    "        self.byte_tracker = sv.ByteTrack(frame_rate=fps)\n",
    "        self.line_zone = line_zone\n",
    "\n",
    "        # These are utilities to draw on the video for visualization\n",
    "        # purposes\n",
    "        self.line_zone_annotator = sv.LineZoneAnnotator(\n",
    "            thickness=2, text_thickness=2, text_scale=1\n",
    "        )\n",
    "        self.bounding_box_annotator = sv.BoxAnnotator()\n",
    "        self.label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "        # We need to pad and resize every frame to match the expected\n",
    "        # input resolution of the model\n",
    "        self.pad_and_resize = PadAndResize(cfg.image_size)\n",
    "\n",
    "        if with_slicing:\n",
    "            self.slicer = sv.InferenceSlicer(\n",
    "                # We slice the image with overlapping slices of\n",
    "                # size half the image size, with an overlap of one sixth\n",
    "                # of the image size\n",
    "                slice_wh=(image_size[0] // 2, image_size[1] // 2),\n",
    "                overlap_wh=((image_size[0] // 6), (image_size[1] // 6)),\n",
    "                # This is the function that will be called on each slice\n",
    "                callback=self._yolo_inference,\n",
    "                overlap_ratio_wh=None,  # this is just to avoid a warning\n",
    "            )\n",
    "        else:\n",
    "            # No slicing, just run YOLO on the whole image\n",
    "            self.slicer = self._yolo_inference\n",
    "\n",
    "    @staticmethod\n",
    "    def yolo_to_sv_detections(yolo_outputs: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Re-organize information in the format expected by the supervision tracker\n",
    "        \"\"\"\n",
    "\n",
    "        yolo_outputs = yolo_outputs.cpu().numpy()\n",
    "\n",
    "        detections = sv.Detections(\n",
    "            # yolo_outputs is a tensor of shape (n_detections, 6)\n",
    "            # where each detection is (class_id, x1, y1, x2, y2, score)\n",
    "            xyxy=yolo_outputs[:, 1:5],  # box coordinates\n",
    "            confidence=yolo_outputs[:, 5],  # confidence score\n",
    "            class_id=yolo_outputs[:, 0].astype(int),  # class id as integer\n",
    "        )\n",
    "\n",
    "        return detections\n",
    "\n",
    "    def _yolo_inference(self, image_slice: np.ndarray) -> sv.Detections:\n",
    "        \"\"\"\n",
    "        Runs inference on one frame and returns results in the format\n",
    "        expected by the supervision tracker\n",
    "        \"\"\"\n",
    "        _, predicts = run_inference_on_one_frame(\n",
    "            self.model, image_slice, self.pad_and_resize\n",
    "        )\n",
    "        return self.yolo_to_sv_detections(predicts)\n",
    "\n",
    "    def run_on_one_frame(self, frame: np.ndarray, index: int) -> np.ndarray:\n",
    "\n",
    "        detections = self.slicer(frame)\n",
    "        # We update the tracker with the new detections\n",
    "        detections = self.byte_tracker.update_with_detections(detections)\n",
    "\n",
    "        if self.line_zone is not None:\n",
    "            # Counting cars and trucks only\n",
    "            # class_id 2 is car, class_id 7 is truck\n",
    "            # You can change this to count other classes\n",
    "            car_detections = detections[(detections.class_id == 2) | (detections.class_id == 7)]\n",
    "            self.line_zone.trigger(car_detections)\n",
    "\n",
    "        labels = [\n",
    "            f\"{cfg.dataset.class_list[int(class_id)]} {tracker_id} {confidence:0.2f}\"\n",
    "            for _, class_id, confidence, tracker_id in zip(\n",
    "                detections.xyxy,\n",
    "                detections.class_id,\n",
    "                detections.confidence,\n",
    "                detections.tracker_id,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        annotated_frame = self.bounding_box_annotator.annotate(\n",
    "            scene=frame.copy(), detections=detections\n",
    "        )\n",
    "\n",
    "        annotated_frame = self.label_annotator.annotate(\n",
    "            scene=annotated_frame, detections=detections, labels=labels\n",
    "        )\n",
    "\n",
    "        if self.line_zone is not None:\n",
    "            # Apply counting annotation to show the line and the\n",
    "            # counts\n",
    "            annotated_frame = self.line_zone_annotator.annotate(\n",
    "                annotated_frame, line_counter=self.line_zone\n",
    "            )\n",
    "\n",
    "        return annotated_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 22:32:14] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üöú Building YOLO                                                            <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 22:32:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üöú Building YOLO                                                            \u001b]8;id=483406;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=367814;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building backbone                                                      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building backbone                                                      \u001b]8;id=758930;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=478728;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building neck                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building neck                                                          \u001b]8;id=340438;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=854257;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building head                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building head                                                          \u001b]8;id=952044;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=646285;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building detection                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building detection                                                     \u001b]8;id=324600;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=318029;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building auxiliary                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building auxiliary                                                     \u001b]8;id=589497;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=542897;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 22:32:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ‚úÖ Success load model &amp; weight                                             <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 22:32:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ‚úÖ Success load model & weight                                             \u001b]8;id=426424;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=326992;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\u001b\\\u001b[2m189\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üß∏ Found no stride of model, performed a dummy test for      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">bounding_box_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">346</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         auto-anchor size                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üß∏ Found no stride of model, performed a dummy test for      \u001b]8;id=384406;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\u001b\\\u001b[2mbounding_box_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=979531;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\u001b\\\u001b[2m346\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         auto-anchor size                                             \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38721eac9e8340ddbac394d4a952223f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing video:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"cars_on_bridge_detected.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_video = \"cars_on_bridge.mp4\"\n",
    "output_video = \"output_detected.m4v\"\n",
    "\n",
    "# Let's define a line in the video\n",
    "# We use a horizontal line in the middle of the bridge\n",
    "_, image_size = get_fps_and_video_size(input_video)\n",
    "START = sv.Point(0, image_size[1] // 4)\n",
    "END = sv.Point(image_size[0], image_size[1] // 4)\n",
    "line_zone = sv.LineZone(\n",
    "    start=START, \n",
    "    end=END,\n",
    "    # We trigger the count when the center of the bounding\n",
    "    # box crosses the line\n",
    "    triggering_anchors=[sv.Position.CENTER],\n",
    ")\n",
    "\n",
    "# This works as before\n",
    "processor = YOLOVideoObjectCounter(video_file=input_video, with_slicing=True, line_zone=line_zone)\n",
    "\n",
    "sv.process_video(\n",
    "    source_path=input_video,\n",
    "    target_path=output_video,\n",
    "    callback=processor.run_on_one_frame,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# Convert from m4v to mp4 so we can display it here\n",
    "!ffmpeg -i {output_video} -c:v libx264 -tag:v avc1 cars_on_bridge_detected.mp4 -y > /dev/null 2>&1\n",
    "\n",
    "display(\n",
    "        Video(\"cars_on_bridge_detected.mp4\", embed=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test it on a different traffic video, where we can see that we count both things going into the area and out from the area. In this case, we can count cars going both directions on a highway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/29/25 22:33:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üöú Building YOLO                                                            <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/29/25 22:33:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üöú Building YOLO                                                            \u001b]8;id=822377;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=860251;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building backbone                                                      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building backbone                                                      \u001b]8;id=854651;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=200700;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building neck                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building neck                                                          \u001b]8;id=684625;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=51285;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building head                                                          <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building head                                                          \u001b]8;id=918019;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=960328;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building detection                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building detection                                                     \u001b]8;id=895424;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=278754;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>   üèó  Building auxiliary                                                     <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m   üèó  Building auxiliary                                                     \u001b]8;id=923356;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=63318;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ‚úÖ Success load model &amp; weight                                             <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">yolo.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ‚úÖ Success load model & weight                                             \u001b]8;id=33421;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py\u001b\\\u001b[2myolo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=59555;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/model/yolo.py#189\u001b\\\u001b[2m189\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> üß∏ Found no stride of model, performed a dummy test for      <a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">bounding_box_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">346</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         auto-anchor size                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m üß∏ Found no stride of model, performed a dummy test for      \u001b]8;id=705445;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py\u001b\\\u001b[2mbounding_box_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=24581;file:///Users/giacomov/develop/cd13331-multimodal/l4/demos/1-yolo/.venv/lib/python3.12/site-packages/yolo/utils/bounding_box_utils.py#346\u001b\\\u001b[2m346\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         auto-anchor size                                             \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4206f33d57e48a4954074e1950e6678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing video:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"traffic_detected.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_video = \"two_lanes_cut.mp4\"\n",
    "output_video = \"traffic_detected.m4v\"\n",
    "\n",
    "\n",
    "# Let's define a line in the video\n",
    "# We use a horizonthal line half way through the image\n",
    "_, image_size = get_fps_and_video_size(input_video)\n",
    "START = sv.Point(0, image_size[1] // 2)\n",
    "END = sv.Point(image_size[0], image_size[1] // 2)\n",
    "line_zone = sv.LineZone(\n",
    "    start=START, \n",
    "    end=END,\n",
    "    # We trigger the count when the center of the bounding\n",
    "    # box crosses the line\n",
    "    triggering_anchors=[sv.Position.CENTER],\n",
    ")\n",
    "\n",
    "processor = YOLOVideoObjectCounter(video_file=input_video, with_slicing=True, line_zone=line_zone)\n",
    "\n",
    "sv.process_video(\n",
    "    source_path=input_video,\n",
    "    target_path=output_video,\n",
    "    callback=processor.run_on_one_frame,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# Convert from m4v to mp4 so we can display it here\n",
    "!ffmpeg -i {output_video} -c:v libx264 -tag:v avc1 traffic_detected.mp4 -y > /dev/null 2>&1\n",
    "\n",
    "display(\n",
    "        Video(\"traffic_detected.mp4\", embed=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this works fairly well! It is not perfect, but we also didn't spend any time optimizing parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1-yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
