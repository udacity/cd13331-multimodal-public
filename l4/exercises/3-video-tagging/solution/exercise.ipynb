{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Video Tagging with Pydantic AI and Gemini\n",
    "\n",
    "In this exercise you will use Pydantic AI with Gemini 2.5 Flash to tag videos.\n",
    "\n",
    "We will pretend we have a small collection of videos we want to use to train a model for planning for a robotic hand. The hand needs to learn basic object manipulations. We want to use video tagging to pre-label and categorize our videos, so downstream Q/A teams can more easily assess them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Environment\n",
    "\n",
    "Before starting, make sure you have placed your Google Gemini credentials in the `.env` file:\n",
    "\n",
    "```bash\n",
    "cp env.example .env\n",
    "```\n",
    "then edit `.env` and modify GEMINI_API_KEY with your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, BinaryContent\n",
    "from IPython.display import Video, display\n",
    "\n",
    "# Load environment variables\n",
    "assert load_dotenv(), \"Please prepare a .env file with your GEMINI_API_KEY\"\n",
    "assert os.getenv(\"GEMINI_API_KEY\"), \"GEMINI_API_KEY not found in .env file\"\n",
    "\n",
    "# Only needed on the Udacity workspace. Comment this out if running on another system.\n",
    "os.environ['HF_HOME'] = '/voc/data/huggingface'\n",
    "os.environ['OLLAMA_MODELS'] = '/voc/data/ollama/cache'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ['PATH'] = f\"/voc/data/ollama/bin:/voc/data/ffmpeg/bin:{os.environ.get('PATH', '')}\"\n",
    "os.environ['LD_LIBRARY_PATH'] = f\"/voc/data/ollama/lib:/voc/data/ffmpeg/lib:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
    "\n",
    "# This is needed to use asyncio within jupyter\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Response Schema\n",
    "\n",
    "As usual, we need to define our response schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import Literal\n",
    "\n",
    "\n",
    "# TODO: Define a video tagging output schema with Pydantic AI\n",
    "# The schema should include:\n",
    "# 1. An overall quality assessment (poor, ok, good)\n",
    "# 2. A list of actions (move sideways, move vertically,\n",
    "#    put object 1 into object 2, pull object 1 out of object 2)\n",
    "# 3. A list of objects present in the video from the following options:\n",
    "#    candle, container, cotton swabs, basket, box, tape, board game, mug,\n",
    "#    jar, slipper, container, scarf, smartphone, pen\n",
    "class VideoTagging(BaseModel):\n",
    "    \"\"\"Structured output for video tagging analysis.\"\"\"\n",
    "\n",
    "    # TODO: remember to assign the type and use the Field function to add \n",
    "    # a description\n",
    "    description: str = Field(\n",
    "        description=\"A detailed description of the action performed in the video\"\n",
    "    )\n",
    "    \n",
    "    # TODO\n",
    "    # HINT: remember you can use Literal[...] to restrict the possible values\n",
    "    quality: Literal[\n",
    "        \"poor\",\n",
    "        \"ok\",\n",
    "        \"good\",\n",
    "    ] = Field(\n",
    "        description=\"Overall technical quality of the video (e.g., resolution, stability)\"\n",
    "    )\n",
    "\n",
    "    # TODO\n",
    "    actions: List[\n",
    "        Literal[\n",
    "            \"move object sideways\",\n",
    "            \"move object vertically\",\n",
    "            \"put object into another object\",\n",
    "            \"pull object out of another object\",\n",
    "        ]\n",
    "    ] = Field(description=\"Action classification\")\n",
    "\n",
    "    # TODO\n",
    "    objects_involved_in_the_action: int = Field(\n",
    "        description=\"Number of distinct objects involved in the action\"\n",
    "    )\n",
    "    \n",
    "    objects_present: List[\n",
    "        Literal[\n",
    "            \"candle\",\n",
    "            \"container\",\n",
    "            \"cotton swabs\",\n",
    "            \"basket\",\n",
    "            \"box\",\n",
    "            \"tape\",\n",
    "            \"board game\",\n",
    "            \"mug\",\n",
    "            \"jar\",\n",
    "            \"slipper\",\n",
    "            \"container\",\n",
    "            \"scarf\",\n",
    "            \"smartphone\",\n",
    "            \"pen\",\n",
    "        ]\n",
    "    ] = Field(\n",
    "        description=\"List of objects present in the video (e.g., person, car, tree)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pydantic AI Agent\n",
    "\n",
    "Set up the agent with Gemini for video content analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.models.google import GoogleModelSettings\n",
    "\n",
    "\n",
    "# Remove thinking to avoid long delays and timeouts\n",
    "settings = GoogleModelSettings(\n",
    "    google_thinking_config={\"thinking_budget\": 0},\n",
    "    temperature=0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# TODO: Create an agent for video tagging using the VideoTagging schema\n",
    "# Use the \"gemini-2.5-flash-lite\" model and the settings defined above\n",
    "# Remember to use output_type to specify the output schema\n",
    "# Craft a short but precise set of instructions for the agent\n",
    "video_agent = Agent(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    output_type=VideoTagging,\n",
    "    instructions=\"\"\"\n",
    "    You are an expert video content analyzer. Watch the provided video carefully and determine:\n",
    "\n",
    "    1. The overall technical quality of the video (poor, ok, good)\n",
    "    2. The actions being performed (choose from push or pull)\n",
    "    3. The number of distinct objects involved in the action\n",
    "    4. The objects present in the video\n",
    "\n",
    "    # Rules:\n",
    "    - PAY ATTENTION to the real action that is being performed on objects, do not get fooled by\n",
    "      merely the movement of the hand\n",
    "    \"\"\",\n",
    "    model_settings=settings,\n",
    "    retries=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function for Video Processing\n",
    "\n",
    "Let's define a helper function to load and format video files for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video_for_analysis(video_path):\n",
    "    \"\"\"Load video file and format it for Pydantic AI.\"\"\"\n",
    "    with open(video_path, 'rb') as f:\n",
    "        video_bytes = f.read()\n",
    "    \n",
    "    # Create binary content for Pydantic AI\n",
    "    # (see note at the end about using File API for longer videos)\n",
    "    video_content = BinaryContent(\n",
    "        data=video_bytes,\n",
    "        media_type='video/mp4'  # Adjust based on your video format\n",
    "    )\n",
    "    \n",
    "    return video_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Analysis\n",
    "\n",
    "Analyze a video file to see the structured description output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video: 175060.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/175060.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['pull object out of another object'],\n",
      " 'description': 'A white string is being pulled out of a green container.',\n",
      " 'objects_involved_in_the_action': 2,\n",
      " 'objects_present': ['container'],\n",
      " 'quality': 'poor'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 161206.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/161206.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['move object sideways'],\n",
      " 'description': 'A hand is seen manipulating a pink and purple object, '\n",
      "                'possibly a scarf, on a textured rug. The object is being '\n",
      "                'moved around, but the specific action is unclear due to the '\n",
      "                'blurriness of the video.',\n",
      " 'objects_involved_in_the_action': 1,\n",
      " 'objects_present': ['scarf'],\n",
      " 'quality': 'poor'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 73015.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/73015.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['move object sideways'],\n",
      " 'description': 'A hand is shown pushing a pink cylindrical object across a '\n",
      "                'white surface with yellow and red markings. The object moves '\n",
      "                'from left to right and out of frame.',\n",
      " 'objects_involved_in_the_action': 1,\n",
      " 'objects_present': ['container'],\n",
      " 'quality': 'ok'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 201684.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/201684.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['pull object out of another object'],\n",
      " 'description': 'A hand reaches into a wicker basket and pulls out a deck of '\n",
      "                'cards.',\n",
      " 'objects_involved_in_the_action': 2,\n",
      " 'objects_present': ['basket', 'board game'],\n",
      " 'quality': 'good'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 130178.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/130178.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['pull object out of another object'],\n",
      " 'description': 'A hand reaches into a glass jar and pulls out a small, '\n",
      "                'light-colored object. The object appears to be a piece of '\n",
      "                'candy or a similar small item. The hand then removes the '\n",
      "                'object from the jar.',\n",
      " 'objects_involved_in_the_action': 2,\n",
      " 'objects_present': ['jar', 'candle'],\n",
      " 'quality': 'ok'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 121844.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/121844.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['move object sideways'],\n",
      " 'description': 'A hand is shown pushing a box of \"Werewolves\" board game '\n",
      "                'sideways.',\n",
      " 'objects_involved_in_the_action': 1,\n",
      " 'objects_present': ['box', 'board game'],\n",
      " 'quality': 'good'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 108542.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/108542.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['put object into another object'],\n",
      " 'description': 'A hand is shown placing a slipper with a cartoon character '\n",
      "                'design onto a rug.',\n",
      " 'objects_involved_in_the_action': 2,\n",
      " 'objects_present': ['slipper'],\n",
      " 'quality': 'good'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 212936.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/212936.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['move object sideways'],\n",
      " 'description': 'A hand is holding a mug with the text \"To infinite energy '\n",
      "                'COFFEE\" and rotating it.',\n",
      " 'objects_involved_in_the_action': 1,\n",
      " 'objects_present': ['mug'],\n",
      " 'quality': 'good'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 33539.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/33539.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['pull object out of another object'],\n",
      " 'description': 'A hand reaches into the frame and pulls a single cotton swab '\n",
      "                'out of a clear plastic container filled with cotton swabs.',\n",
      " 'objects_involved_in_the_action': 2,\n",
      " 'objects_present': ['cotton swabs', 'container'],\n",
      " 'quality': 'ok'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 194530.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/194530.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['put object into another object'],\n",
      " 'description': 'A hand is shown placing a blue pen on top of a black '\n",
      "                'smartphone. The pen is positioned horizontally across the '\n",
      "                'phone. The video quality is poor due to low resolution and '\n",
      "                'shaky camera work.',\n",
      " 'objects_involved_in_the_action': 2,\n",
      " 'objects_present': ['smartphone', 'pen'],\n",
      " 'quality': 'poor'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Original video: 34137.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../videos/34137.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing video content...\n",
      "\n",
      "Video Analysis Results:\n",
      "{'actions': ['pull object out of another object'],\n",
      " 'description': 'A hand is shown picking up a cylindrical object with a dark '\n",
      "                'red, patterned surface. The object appears to be a candle. '\n",
      "                'The hand then moves the object slightly to the right before '\n",
      "                'placing it back down.',\n",
      " 'objects_involved_in_the_action': 1,\n",
      " 'objects_present': ['candle'],\n",
      " 'quality': 'ok'}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Video, display\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "videos = Path(\"../videos\").glob(\"*.mp4\")\n",
    "\n",
    "for video_path in videos:\n",
    "    print(f\"Original video: {video_path.name}\")\n",
    "    display(Video(str(video_path)))\n",
    "    \n",
    "    video_content = load_video_for_analysis(video_path)\n",
    "    \n",
    "    print(\"\\nAnalyzing video content...\")\n",
    "\n",
    "    # TODO: run the agent on the video\n",
    "    result = video_agent.run_sync(\n",
    "        [\"Please provide a detailed description of this video.\", video_content]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nVideo Analysis Results:\")\n",
    "    pprint(result.output.model_dump(), width=80, depth=None)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3-video-tagging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
